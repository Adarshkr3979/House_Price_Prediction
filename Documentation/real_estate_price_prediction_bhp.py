# -*- coding: utf-8 -*-
"""Real Estate Price Prediction_BHP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eAbatUQEsT70d37UkOU-zZLQPqMpVdoh

# **1. Importing necessary Libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt
# %matplotlib inline
import matplotlib 
matplotlib.rcParams["figure.figsize"] = (20,10)

"""# 2. Reading Data"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import io
df1 = pd.read_csv(io.BytesIO(uploaded['Bengaluru_House_Data.csv']))
df1.head()

df1.shape

# draw Heat Map 

plt.figure(figsize=(15, 10))
sns.heatmap(df1.corr(), annot=True)
plt.title('Heat Map', size=20)
plt.yticks(rotation = 0)
plt.show()

plt.figure(figsize=(30,10))

plt.subplot(1,2,1)
plt.title('House Price Distribution Plot')
sns.distplot(df1["price"])

plt.subplot(1,2,2)
plt.title('House Price Spread')
sns.boxplot(y=df1["price"])

plt.show()

import seaborn as sns
plt.figure(figsize=(20, 5))
sns.barplot(x = df1['location'], y = df1.price)
plt.xticks( horizontalalignment="center",rotation = 90 )
plt.xlabel("Location")
plt.title("Location - Price")
plt.ylabel("Price\n")

plt.show()

# make function for count plot and scatter plots for Categorical features

def Categorical_Plot(column,rotation=0):
    
        plt.figure(figsize=(30, 10))
        plt.subplot(1, 2, 1)
        pd.value_counts(df1[column]).plot(kind='bar')
        plt.xticks( horizontalalignment="center", fontsize=15, rotation = rotation )
        plt.xlabel(f"\n{str(column)}", fontsize=15)
        plt.ylabel("Count\n", fontsize=15)
        plt.yticks(fontsize = 15)
        plt.title(f"{str(column)} - Count\n", fontsize = 15)

        plt.subplot(1, 2, 2)
        sns.barplot(x = df1[column], y = df1.price)
        plt.xticks( horizontalalignment="center", fontsize=15, rotation = rotation )
        plt.xlabel(f"\n{str(column)}", fontsize=15)
        plt.yticks(fontsize = 15)
        plt.title(f"{str(column)} - Price\n", fontsize = 15)
        plt.ylabel("Price\n", fontsize=15)

        plt.show()
        print()

Categorical_Plot("bath")

Categorical_Plot("balcony")

plt.figure(figsize=(25, 5))
sns.pairplot(df1)
plt.show()

df1.hist(figsize=(10,10));

df1.columns

df1['area_type'].unique()

df1['area_type'].value_counts()

df2 = df1.drop(['area_type','society','balcony','availability'],axis='columns')
df2.shape

"""# Data Cleaning: Handle NA values"""

df2.isnull().sum()

df2.shape

df3 = df2.dropna()
df3.isnull().sum()

df3.shape

"""# Add new feature(integer) for bhk (Bedrooms Hall Kitchen)"""

df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))
df3.bhk.unique()

"""# Explore total_sqft feature"""

def is_float(x):
    try:
        float(x)
    except:
        return False
    return True

df3[~df3['total_sqft'].apply(is_float)].head(10)

"""Above shows that total_sqft can be a range (e.g. 2100-2850). For such case we can just take average of min and max value in the range. There are other cases such as 34.46Sq. Meter which one can convert to square ft using unit conversion. I am going to just drop such corner cases to keep things simple"""

def convert_sqft_to_num(x):
    tokens = x.split('-')
    if len(tokens) == 2:
        return (float(tokens[0])+float(tokens[1]))/2
    try:
        return float(x)
    except:
        return None

df4 = df3.copy()
df4.total_sqft = df4.total_sqft.apply(convert_sqft_to_num)
df4 = df4[df4.total_sqft.notnull()]
df4.head(2)

"""For below row, it shows total_sqft as 2475 which is an average of the range 2100-2850"""

df4.loc[30]

(2100+2850)/2

"""# Add new feature called price per square feet"""

df5 = df4.copy()
df5['price_per_sqft'] = df5['price']*100000/df5['total_sqft']
df5.head()

df5_stats = df5['price_per_sqft'].describe()
df5_stats

"""Examine locations which is a categorical variable. We need to apply dimensionality reduction technique here to reduce number of locations"""

df5.location = df5.location.apply(lambda x: x.strip())
location_stats = df5['location'].value_counts(ascending=False)
location_stats

location_stats.values.sum()

len(location_stats[location_stats>10])

len(location_stats)

len(location_stats[location_stats<=10])

"""# Dimensionality Reduction

Any location having less than 10 data points should be tagged as "other" location. This way number of categories can be reduced by huge amount. Later on when we do one hot encoding, it will help us with having fewer dummy columns
"""

location_stats_less_than_10 = location_stats[location_stats<=10]
location_stats_less_than_10

len(df5.location.unique())

df5.location = df5.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)
len(df5.location.unique())

df5.head(10)

"""# Outlier Removal Using Business Logic"""

df5[df5.total_sqft/df5.bhk<300].head()

df5.shape

df6 = df5[~(df5.total_sqft/df5.bhk<300)]
df6.shape

"""# Outlier Removal Using Standard Deviation and Mean"""

df6.price_per_sqft.describe()

def remove_pps_outliers(df):
    df_out = pd.DataFrame()
    for key, subdf in df.groupby('location'):
        m = np.mean(subdf.price_per_sqft)
        st = np.std(subdf.price_per_sqft)
        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]
        df_out = pd.concat([df_out,reduced_df],ignore_index=True)
    return df_out
df7 = remove_pps_outliers(df6)
df7.shape

"""Let's check if for a given location how does the 2 BHK and 3 BHK property prices look like"""

def plot_scatter_chart(df,location):
    bhk2 = df[(df.location==location) & (df.bhk==2)]
    bhk3 = df[(df.location==location) & (df.bhk==3)]
    matplotlib.rcParams['figure.figsize'] = (15,10)
    plt.scatter(bhk2.total_sqft,bhk2.price,color='lightcoral',label='2 BHK', s=50)
    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='darkslategray',label='3 BHK', s=50)
    plt.xlabel("Total Square Feet Area")
    plt.ylabel("Price (Lakh Indian Rupees)")
    plt.title(location)
    plt.legend()
    
plot_scatter_chart(df7,"Rajaji Nagar")

"""Remove those 2 BHK apartments whose price_per_sqft is less than mean price_per_sqft of 1 BHK apartment"""

def remove_bhk_outliers(df):
    exclude_indices = np.array([])
    for location, location_df in df.groupby('location'):
        bhk_stats = {}
        for bhk, bhk_df in location_df.groupby('bhk'):
            bhk_stats[bhk] = {
                'mean': np.mean(bhk_df.price_per_sqft),
                'std': np.std(bhk_df.price_per_sqft),
                'count': bhk_df.shape[0]
            }
        for bhk, bhk_df in location_df.groupby('bhk'):
            stats = bhk_stats.get(bhk-1)
            if stats and stats['count']>5:
                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)
    return df.drop(exclude_indices,axis='index')
df8 = remove_bhk_outliers(df7)
# df8 = df7.copy()
df8.shape

"""Plot same scatter chart again to visualize price_per_sqft for 2 BHK and 3 BHK properties"""

plot_scatter_chart(df8,"Rajaji Nagar")

"""Based on above charts the data points highlighted in red below are outliers and they are being removed due to remove_bhk_outliers function"""

import matplotlib
matplotlib.rcParams["figure.figsize"] = (20,10)
plt.hist(df8.price_per_sqft,rwidth=0.8, color = "brown")
plt.xlabel("Price Per Square Feet")
plt.ylabel("Count")

"""# Outlier Removal Using Bathrooms Feature"""

df8.bath.unique()

plt.hist(df8.bath,rwidth=0.8, color = "burlywood")
plt.xlabel("Number of bathrooms")
plt.ylabel("Count")

df8[df8.bath>10]

"""It is unusual to have 2 more bathrooms than number of bedrooms in a home"""

df8[df8.bath>df8.bhk+2]

df9 = df8[df8.bath<df8.bhk+2]
df9.shape

df9.head(2)

df10 = df9.drop(['size','price_per_sqft'],axis='columns')
df10.head(3)

"""# Use One Hot Encoding For Location"""

dummies = pd.get_dummies(df10.location)
dummies.head(3)

df11 = pd.concat([df10,dummies.drop('other',axis='columns')],axis='columns')
df11.head()

df12 = df11.drop('location',axis='columns')
df12.head(2)

"""# Build a Model Now......."""

df12.shape

X = df12.drop(['price'],axis='columns')
X.head(3)

X.shape

y = df12.price
y.head(3)

len(y)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)

from sklearn.linear_model import LinearRegression
lr_clf = LinearRegression()
lr_clf.fit(X_train,y_train)
lr_clf.score(X_test,y_test)

"""# Use K Fold cross validation to measure accuracy of our LinearRegression **model**"""

from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import cross_val_score

cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)

cross_val_score(LinearRegression(), X, y, cv=cv)

"""# **Find best model using GridSearchCV**"""

import pandas as pd
from sklearn.model_selection import GridSearchCV, ShuffleSplit, cross_val_score
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import StandardScaler

def find_best_model_using_gridsearchcv(X,y):

    algos = {
        'linear_regression' : {
            'model': LinearRegression(),
            'params': {
                'copy_X': [True, False],
                'fit_intercept': [True, False],
                'n_jobs': [None, -1],
                'positive': [False],
                # 'normalize': [True, False],
            }
        },
        'lasso': {
            'model': Lasso(),
            'params': {
                'alpha': [1,2],
                'selection': ['random', 'cyclic']
            }
        },
        'decision_tree': {
            'model': DecisionTreeRegressor(),
            'params': {
                'criterion' : ['mse','friedman_mse'],
                'splitter': ['best','random']
            }
        }
    }
    scores = []
    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
    for algo_name, config in algos.items():
        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)
        gs.fit(X,y)
        scores.append({
            'model': algo_name,
            'best_score': gs.best_score_,
            'best_params': gs.best_params_
        })

    return pd.DataFrame(scores,columns=['model','best_score','best_params'])

find_best_model_using_gridsearchcv(X,y)

"""# Test the model for few properties"""

def predict_price(location,sqft,bath,bhk):    
    loc_index = np.where(X.columns==location)[0][0]

    x = np.zeros(len(X.columns))
    x[0] = sqft
    x[1] = bath
    x[2] = bhk
    if loc_index >= 0:
        x[loc_index] = 1

    return lr_clf.predict([x])[0]

print(predict_price('1st Phase JP Nagar', 1000, 2, 3).round(3),'Lakhs')

print(predict_price('1st Phase JP Nagar',1450, 4, 4).round(3),'Lakhs')

print(predict_price('Indira Nagar',1000, 2, 2).round(3),'Lakhs')

print(predict_price('Indira Nagar',1500, 5, 5).round(3),'Lakhs')